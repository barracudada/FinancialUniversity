{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de3a75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0f3888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_data = []\n",
    "period_data_pct = []\n",
    "period_data_pct_m = []\n",
    "\n",
    "period_rate = []\n",
    "period_msci = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d724aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./data/data.xlsx')\n",
    "data['Unnamed: 0'] = pd.to_datetime(data['Unnamed: 0'])\n",
    "data = data.set_index('Unnamed: 0')\n",
    "data.index.name = None\n",
    "\n",
    "#data slicer\n",
    "indmin = data.groupby(data.index.to_period('M')).apply(lambda x: x.index.min()).values\n",
    "indmax = data.groupby(data.index.to_period('M')).apply(lambda x: x.index.max()).values\n",
    "\n",
    "for i in range(0, 61):\n",
    "    pre = data.loc[indmin[i]:indmax[i+11]]\n",
    "    \n",
    "    if len(pre) == 366:\n",
    "        pre = pre[1:]\n",
    "    period_data.append(pre)\n",
    "    \n",
    "    period_data_pct.append(pre.pct_change().dropna())\n",
    "    \n",
    "pre = data.groupby([data.index.year, data.index.month]).agg([\"first\", \"last\"])\n",
    "\n",
    "data_pct_m = pd.DataFrame(index = data.groupby(data.index.to_period('M')).apply(lambda x: x.index.max()).values\n",
    "                     , columns = data.columns)\n",
    "for i in data.columns:\n",
    "    data_pct_m[i] = ( (pre[i]['last'] - pre[i]['first']) / pre[i]['first'] ).values\n",
    "\n",
    "for i in range(0, 61):\n",
    "    period_data_pct_m.append(data_pct_m.loc[indmin[i]:indmax[i+11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48e969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = pd.read_csv('./data/rates.csv', sep=',')\n",
    "rate = rate[['Дата', 'Цена']]\n",
    "rate[['Day', 'Month', 'Year']] = rate['Дата'].str.split('.',expand=True)\n",
    "rate['Date'] = rate['Day'] + '-' + rate['Month'] + '-' + rate['Year']\n",
    "rate = rate.drop(['Дата', 'Day', 'Month', 'Year'], axis=1)\n",
    "rate['Date'] = pd.to_datetime(rate['Date'], format='%d-%m-%Y')\n",
    "rate = rate.set_index('Date')\n",
    "rate.index.name = None\n",
    "rate['Цена'] = rate['Цена'].str.replace(',', '.')\n",
    "rate['Цена'] = rate['Цена'].astype(float) / 100\n",
    "rate.rename(columns={'Цена': 'Rate'}, inplace=True)\n",
    "rate = rate.sort_index(ascending=True)\n",
    "\n",
    "for i in range(0, 61):\n",
    "    period_rate.append(rate.iloc[11+i, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1aac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "msci = pd.read_csv('./data/MSCI.csv', sep=',')\n",
    "msci = msci[['Дата', 'Цена']]\n",
    "msci[['Day', 'Month', 'Year']] = msci['Дата'].str.split('.',expand=True)\n",
    "msci['Date'] = msci['Day'] + '-' + msci['Month'] + '-' + msci['Year']\n",
    "msci = msci.drop(['Дата', 'Day', 'Month', 'Year'], axis=1)\n",
    "msci['Date'] = pd.to_datetime(msci['Date'], format='%d-%m-%Y')\n",
    "msci = msci.set_index('Date')\n",
    "msci.index.name = None\n",
    "msci['Цена'] = msci['Цена'].str.replace('.', '')\n",
    "msci['Цена'] = msci['Цена'].str.replace(',', '.')\n",
    "msci['Цена'] = msci['Цена'].astype(float)\n",
    "msci.rename(columns={'Цена': 'MSCI'}, inplace=True)\n",
    "msci = msci.sort_index(ascending=True)\n",
    "\n",
    "for i in range(0, 61):\n",
    "    period_msci.append(msci.loc[indmin[i]:indmax[i+11]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3564e0c",
   "metadata": {},
   "source": [
    "Portfolio functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc479b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypfopt import EfficientFrontier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f79a4dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ef_dots(mu, cov_m):\n",
    "    ef = EfficientFrontier(mu, cov_m, solver='SCS')\n",
    "    mu_min = min(i for i in mu if i > 0)\n",
    "    target_returns = np.linspace(mu_min*1.01, mu.max()*0.99, 100)\n",
    "    sigmas = []\n",
    "    weights = []\n",
    "    for target_return in target_returns:\n",
    "        ef.efficient_return(target_return)\n",
    "        weight = ef.clean_weights()\n",
    "        weights.append(list(weight.values()))\n",
    "        sigmas.append(ef.portfolio_performance()[1])\n",
    "    cut = list(map(lambda i: i > np.diag(cov_m).min(), sigmas)).index(True)\n",
    "    return [target_returns[cut:], sigmas[cut:], weights[cut:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5966f767",
   "metadata": {},
   "source": [
    "Minimum Risk Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc68bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_risk_portfolio(pdata_pct_m):\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    #Min Risk portfolio\n",
    "    min_risk = [ef_dots[0][0], ef_dots[1][0], ef_dots[2][0]]\n",
    "    return ef_dots, min_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b761ba3",
   "metadata": {},
   "source": [
    "Max Sharpe Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ac8638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_sharpe_portfolio(pdata_pct_m):\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    #Max Sharpe portfolio\n",
    "    sharpe_values = []\n",
    "    for w in ef_dots[2]:\n",
    "        sharpe_values.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    max_sharpe = sharpe_values.index(max(sharpe_values))\n",
    "    return ef_dots, [ef_dots[0][max_sharpe], ef_dots[1][max_sharpe], ef_dots[2][max_sharpe]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121769a",
   "metadata": {},
   "source": [
    "Max Treynor Ratio Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8152ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta, dweibull, gamma, gumbel_r, lognorm, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d0ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_cov(pdata_pct_m):\n",
    "    median_cov_m = []\n",
    "    for col in pdata_pct_m.columns:\n",
    "        median_cov_m.append(np.median( np.abs(pdata_pct_m[col] - np.median(pdata_pct_m[col])) ))\n",
    "    return np.diag(median_cov_m)\n",
    "\n",
    "def spearman_corr(pdata_pct_m):\n",
    "    return pdata_pct_m.corr(method='spearman')\n",
    "\n",
    "def median_cov_spearman_corr_matrix(pdata_pct_m):\n",
    "    median_cov_matrix = median_cov(pdata_pct_m)\n",
    "    spearman_corr_matrix = spearman_corr(pdata_pct_m)\n",
    "    \n",
    "    cov_max_tr = median_cov_matrix @ spearman_corr_matrix @ median_cov_matrix\n",
    "    cov_max_tr.columns = pdata_pct_m.columns\n",
    "    cov_max_tr.index = pdata_pct_m.columns\n",
    "    return cov_max_tr\n",
    "\n",
    "#Maximum Likelihood estimation for first moment\n",
    "\n",
    "def get_mom_from_mle(x, n=1):\n",
    " \n",
    "    def beta_fit(x):\n",
    "        a,b,c,d = beta.fit(x, method=\"MLE\")\n",
    "        mle = np.log(beta.pdf(x, a, b,c ,d)).sum()\n",
    "        mom1 = beta.stats(a, b, c, d, moments='mvsk')[0]\n",
    "        mom2 = beta.stats(a, b, c, d, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "\n",
    "    def dweibull_fit(x):\n",
    "        a,b,c = dweibull.fit(x, method=\"MLE\")\n",
    "        mle = np.log(dweibull.pdf(x, a, b,c )).sum()\n",
    "        mom1 = dweibull.stats(a, b, c, moments='mvsk')[0]\n",
    "        mom2 = dweibull.stats(a, b, c, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "\n",
    "    def gamma_fit(x):\n",
    "        a,b,c = gamma.fit(x, method=\"MLE\")\n",
    "        mle = np.log(gamma.pdf(x, a, b,c )).sum()\n",
    "        mom1 = gamma.stats(a, b, c, moments='mvsk')[0]\n",
    "        mom2 = gamma.stats(a, b, c, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "\n",
    "    def gumbel_fit(x):\n",
    "        a,b = gumbel_r.fit(x, method=\"MLE\")\n",
    "        mle = np.log(gumbel_r.pdf(x, a, b)).sum()\n",
    "        mom1 = gumbel_r.stats(a, b, moments='mvsk')[0]\n",
    "        mom2 = gumbel_r.stats(a, b, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "\n",
    "    def lognorm_fit(x):\n",
    "        a,b,c = lognorm.fit(x, method=\"MLE\")\n",
    "        mle = np.log(lognorm.pdf(x, a, b,c)).sum()\n",
    "        mom1 = lognorm.stats(a, b, c, moments='mvsk')[0]\n",
    "        mom2 = lognorm.stats(a, b, c, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "\n",
    "    def norm_fit(x):\n",
    "        a,b = norm.fit(x, method=\"MLE\")\n",
    "        mle = np.log(norm.pdf(x, a, b)).sum()\n",
    "        mom1 = norm.stats(a, b, moments='mvsk')[0]\n",
    "        mom2 = norm.stats(a, b, moments='mvsk')[1]\n",
    "        return [mle, mom1, mom2]\n",
    "    \n",
    "    try: \n",
    "        bf = beta_fit(x)\n",
    "    except:\n",
    "        bf = [0, np.mean(x), np.var(x)]\n",
    "    \n",
    "    result = [bf, dweibull_fit(x), gamma_fit(x), gumbel_fit(x), lognorm_fit(x), norm_fit(x)]\n",
    "    result = max(result, key=lambda x: x[0])\n",
    "    if n == 1:\n",
    "        return result[1]\n",
    "    if n == 2:\n",
    "        return result[2]\n",
    "    \n",
    "def exp_ret_from_mle(pdata_pct_m):\n",
    "    exp_ret_from_mle_vector = []\n",
    "    for col in pdata_pct_m.columns:\n",
    "        data = pdata_pct_m[col].values\n",
    "        exp_ret_from_mle_vector.append( get_mom_from_mle(data, n=1) )\n",
    "    for j, i in enumerate(exp_ret_from_mle_vector):\n",
    "        if i > 1:\n",
    "            exp_ret_from_mle_vector[j] = 0.005\n",
    "    exp_ret_from_mle_vector = pd.Series(exp_ret_from_mle_vector, index=pdata_pct_m.columns)\n",
    "    return exp_ret_from_mle_vector\n",
    "\n",
    "def get_asset_betas(pdata_pct_m, msci_y):\n",
    "    betas = []\n",
    "    for col in pdata_pct_m.columns:\n",
    "        betas.append( np.cov(msci_y.values, pdata_pct_m[col], ddof=0)[0][1] / np.var(msci_y) )\n",
    "    return np.array(betas)\n",
    "\n",
    "def get_max_treynor_portfolio(pdata_pct_m, msci_y):\n",
    "    mu = exp_ret_from_mle(pdata_pct_m)\n",
    "    cov_m = median_cov_spearman_corr_matrix(pdata_pct_m)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    #Max Treynor portfolio\n",
    "    treynor_values = []\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y)\n",
    "    for w in ef_dots[2]:\n",
    "        treynor_values.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    max_treynor = treynor_values.index(max(treynor_values))\n",
    "    return ef_dots, [ef_dots[0][max_treynor], ef_dots[1][max_treynor], ef_dots[2][max_treynor]], mu, cov_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abefd46",
   "metadata": {},
   "source": [
    "Maximum Sortino Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a787f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capm_exp_ret(pdata_pct_m, msci_y, r_f):\n",
    "    mu = []\n",
    "    for i, col in enumerate(pdata_pct_m.columns):\n",
    "        beta_reg, alpha_reg = np.polyfit(x = pdata_pct_m[col].values[1:] , y = msci_y.pct_change().values[1:] , deg = 1)\n",
    "        mu.append(alpha_reg - r_f + beta_reg * (msci_y.pct_change().mean() - r_f))\n",
    "    if len([i for i in mu if i > 0]) < 3:\n",
    "        rnd = np.random.randint(0, 200, 3)\n",
    "        mu[rnd[0]] = np.random.uniform(0.001, 0.02) \n",
    "        mu[rnd[1]] = np.random.uniform(0.001, 0.02) \n",
    "        mu[rnd[2]] = np.random.uniform(0.001, 0.02) \n",
    "    return pd.Series(mu, index=pdata_pct_m.columns)\n",
    "\n",
    "def semi_cov_matrix(pdata_pct_m, r_f):\n",
    "    semi_cov = []\n",
    "    for col in pdata_pct_m.columns:\n",
    "        semi_cov.append((np.minimum(pdata_pct_m[col] - r_f, 0)**2).mean())\n",
    "    return np.diag(semi_cov)\n",
    "\n",
    "def kendall_corr(pdata_pct_m):\n",
    "    return pdata_pct_m.corr(method='kendall')\n",
    "\n",
    "def semi_cov_kendall_corr_matrix(pdata_pct_m, r_f):\n",
    "    cov_m = semi_cov_matrix(pdata_pct_m, r_f) @ kendall_corr(pdata_pct_m) @ semi_cov_matrix(pdata_pct_m, r_f)\n",
    "    cov_m.index = pdata_pct_m.columns\n",
    "    cov_m.columns = pdata_pct_m.columns\n",
    "    return cov_m\n",
    "\n",
    "def get_max_sortino_portfolio(pdata_pct_m, msci_y, r_f):\n",
    "    mu = capm_exp_ret(pdata_pct_m, msci_y, r_f)\n",
    "    cov_m = semi_cov_kendall_corr_matrix(pdata_pct_m, r_f)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    #Max Sortino portfolio\n",
    "    sortino_values = []\n",
    "    for w in ef_dots[2]:\n",
    "        sortino_values.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    max_sortino = sortino_values.index(max(sortino_values))\n",
    "    return ef_dots, [ef_dots[0][max_sortino], ef_dots[1][max_sortino], ef_dots[2][max_sortino]], mu, cov_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7091072",
   "metadata": {},
   "source": [
    "Maximum Stuzer Ratio Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af81dcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "967766dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arma_exp_ret(pdata, pdata_pct):\n",
    "    mu = []\n",
    "    for i in tqdm(pdata_pct.columns):\n",
    "        model = ARIMA(pdata_pct[i], order=(9, 0, 7), freq='D')\n",
    "        model_fit = model.fit()\n",
    "        start = len(pdata_pct[i])\n",
    "        end = start + 30\n",
    "        predictions = model_fit.predict(start=start, end=end)\n",
    "        clear_output(wait=True)\n",
    "        prev_v = pdata[i][-1]\n",
    "        for j in predictions:\n",
    "            if j != 0:\n",
    "                prev_v = (j + 1) * prev_v\n",
    "            else:\n",
    "                pass\n",
    "        mu.append((prev_v - pdata[i][-1]) / pdata[i][-1])\n",
    "    return pd.Series(mu, index=pdata_pct.columns)\n",
    "\n",
    "def var_from_mle(pdata_pct_m):\n",
    "    var = []\n",
    "    for col in pdata_pct_m.columns:\n",
    "        x = pdata_pct_m[col].values\n",
    "        var.append( get_mom_from_mle(x, n=2) )\n",
    "    return np.diag(var)\n",
    "\n",
    "def arch_copula_corr(p=0):\n",
    "    archimedian_cor= np.loadtxt('correlation_analysis/intermediate_data/archimedian/archimedian_cors%s.gz' %p, delimiter=',')\n",
    "    return archimedian_cor\n",
    "\n",
    "def var_mle_arch_copula_corr_matrix(pdata_pct_m, p=0):\n",
    "    var = var_from_mle(pdata_pct_m)\n",
    "    corr_m = arch_copula_corr(p=p)\n",
    "    cov_m = pd.DataFrame(var @ corr_m @ var)\n",
    "    cov_m.index = pdata_pct_m.columns\n",
    "    cov_m.columns = pdata_pct_m.columns\n",
    "    return cov_m.round(6)\n",
    "\n",
    "def get_max_stuzer_portfolio(pdata, pdata_pct, pdata_pct_m, r_f, p=0):\n",
    "    mu = arma_exp_ret(pdata, pdata_pct)\n",
    "    cov_m = var_mle_arch_copula_corr_matrix(pdata_pct_m, p=p)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    #Max Stuzer Portfolio\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    stuzer_values = []\n",
    "    for w in ef_dots[2]:\n",
    "        res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "        I_st = res.x[0]\n",
    "        stuzer_values.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    max_stuzer = stuzer_values.index(max(stuzer_values))\n",
    "    clear_output(wait=True)\n",
    "    return ef_dots, [ef_dots[0][max_stuzer], ef_dots[1][max_stuzer], ef_dots[2][max_stuzer]], mu, cov_m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb29e5fc",
   "metadata": {},
   "source": [
    "Min VaR Portfolio (delta-norm method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e67567a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e220b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, preq_len):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.preq_len = preq_len\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        out = out[:, -30:, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "def eval_lstm_model():\n",
    "    input_size = 200\n",
    "    hidden_size = 256\n",
    "    num_layers = 2\n",
    "    output_size = 200\n",
    "    preq_len = 30\n",
    "    \n",
    "    model = LSTMModel(input_size, hidden_size, num_layers, input_size, preq_len).to(device)\n",
    "    model.load_state_dict(torch.load('models/lstm_predict.pth', weights_only=True))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def lstm_exp_ret(pdata_pct):\n",
    "    model = eval_lstm_model()\n",
    "    clear_output(wait=True)\n",
    "    pre = np.array([pdata_pct.values.astype(np.float32)])\n",
    "    predicted = model(torch.from_numpy(pre))\n",
    "    predicted = predicted.detach().numpy()\n",
    "    predicted = predicted.reshape(predicted.shape[1], predicted.shape[2])\n",
    "    predicted = pd.DataFrame(predicted)\n",
    "    predicted = predicted.mean()\n",
    "    predicted.index = pdata_pct.columns\n",
    "    return predicted\n",
    "\n",
    "def var_from_kde(pdata_pct):\n",
    "    var = []\n",
    "    for col in pdata_pct.columns:\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(pd.DataFrame(pdata_pct[col]))\n",
    "        samples = kde.sample(n_samples=1000)\n",
    "        var_col = pd.Series([i[0] for i in samples]).var()\n",
    "        var.append(var_col)\n",
    "    return np.diag(var)\n",
    "\n",
    "def glasso_corr(p=0):\n",
    "    glasso_cor = np.loadtxt('correlation_analysis/intermediate_data/glasso_cors/glasso_cors%s.gz' %p, delimiter=',')\n",
    "    return glasso_cor\n",
    "\n",
    "def var_kde_glasso_corr_matrix(pdata_pct_m, p=0):\n",
    "    var = var_from_kde(pdata_pct_m)\n",
    "    corr_m = glasso_corr(p=p)\n",
    "    cov_m = pd.DataFrame(var @ corr_m @ var)\n",
    "    cov_m.index = pdata_pct_m.columns\n",
    "    cov_m.columns = pdata_pct_m.columns\n",
    "    return cov_m\n",
    "\n",
    "def get_min_var_portfolio(pdata, pdata_pct, pdata_pct_m, p=0, alpha=0.95, days=30):\n",
    "    mu = lstm_exp_ret(pdata_pct)\n",
    "    cov_m = var_kde_glasso_corr_matrix(pdata_pct_m, p=p)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    value_at_risk = []\n",
    "    for w in ef_dots[2]:\n",
    "        portfolio_ret = w @ mu\n",
    "        portfolio_vol = np.sqrt(w @ cov_m @ w )\n",
    "        var = abs((portfolio_ret * days - abs(norm.ppf(1-alpha)) * portfolio_vol * np.sqrt(days)))\n",
    "        value_at_risk.append( var )\n",
    "    min_var = value_at_risk.index(min(value_at_risk))\n",
    "    return ef_dots, [ef_dots[0][min_var], ef_dots[1][min_var], ef_dots[2][min_var]], mu, cov_m, value_at_risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0ed80",
   "metadata": {},
   "source": [
    "Minimum CVaR Portfolio (historical modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de4ae260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522ecd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTimeSeriesForecaster(nn.Module):\n",
    "    def __init__(self, input_size=365, output_size=30):\n",
    "        super(CNNTimeSeriesForecaster, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # Рассчитываем размер после пулинга\n",
    "        self.flatten_size = 128 * (input_size // 8)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.flatten_size, 256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(256, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def eval_cnn_model(index):\n",
    "    model = CNNTimeSeriesForecaster(input_size=365, output_size=30).to(device)\n",
    "    model.load_state_dict(torch.load('models/cnn_models/cnn%s.pth' %index, weights_only=True))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def cnn_asset_exp_ret(index, passet_returns):\n",
    "    model = eval_cnn_model(index)\n",
    "    clear_output(wait=True)\n",
    "    pre = np.array([passet_returns.values.astype(np.float32)])\n",
    "    predicted = model(torch.from_numpy(pre))\n",
    "    predicted = predicted.detach().numpy()[0]\n",
    "    return predicted[-1]\n",
    "\n",
    "def cnn_exp_ret(pdata_pct):\n",
    "    mu = []\n",
    "    for index, i in enumerate(pdata_pct.columns):\n",
    "        mu.append(cnn_asset_exp_ret(index, pdata_pct[i]))\n",
    "    return pd.Series(mu, index=pdata_pct.columns)\n",
    "\n",
    "def var_from_garch(pdata_pct):\n",
    "    var = []\n",
    "    for col in pdata_pct.columns:\n",
    "        model = arch_model(pdata_pct[col], vol='Garch', p=1, q=1)\n",
    "        results = model.fit(update_freq=5)\n",
    "        forecast = results.forecast(horizon=30)\n",
    "        var.append(np.sqrt(forecast.variance.values.sum()))\n",
    "        clear_output(wait=True)\n",
    "    return var\n",
    "\n",
    "def kpca_corr(p=0):\n",
    "    kpca_cor = np.loadtxt('correlation_analysis/intermediate_data/kpca/X_kcpa_copula_cor_large_list2%s.gz' %p, delimiter=',')\n",
    "    scaller = MinMaxScaler(feature_range=(-1, 1))\n",
    "    kpca_cor = scaller.fit_transform(kpca_cor)\n",
    "    return np.corrcoef(kpca_cor)\n",
    "\n",
    "def var_garch_kpca_corr_matrix(pdata_pct_m, p=0):\n",
    "    var = var_from_garch(pdata_pct)\n",
    "    corr_m = kpca_corr(p=p)\n",
    "    cov_m = pd.DataFrame(np.diag(var) @ corr_m @ np.diag(var))\n",
    "    cov_m.index = pdata_pct_m.columns\n",
    "    cov_m.columns = pdata_pct_m.columns\n",
    "    return cov_m\n",
    "\n",
    "def get_min_cvar_portfolio(pdata_pct, p=1, alpha=0.95):\n",
    "    mu = cnn_exp_ret(pdata_pct)\n",
    "    cov_m = var_garch_kpca_corr_matrix(pdata_pct_m, p=p)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    var_p = []\n",
    "    cvar_p = []\n",
    "    for w in ef_dots[2]:\n",
    "        portfolio_ret = pdata_pct @ w\n",
    "        var_level = int((1 - alpha) * len(mu))\n",
    "        sorted_ret = np.sort(portfolio_ret)\n",
    "        var = -sorted_ret[var_level]\n",
    "        cvar = -np.mean(sorted_ret[:var_level])\n",
    "        var_p.append(var)\n",
    "        cvar_p.append(cvar)\n",
    "    min_cvar = cvar_p.index(min(cvar_p))\n",
    "    return ef_dots, [ef_dots[0][min_cvar], ef_dots[1][min_cvar], ef_dots[2][min_cvar]], mu, cov_m, cvar_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e2f13b",
   "metadata": {},
   "source": [
    "Maximum r/CVaR Portfolio (Monte Carlo modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c719603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3eb8acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_exp_ret(pdata):\n",
    "    mu = []\n",
    "    for i in pdata.columns:\n",
    "        X_train = np.array([pdata[i].values[:-30]])\n",
    "        y_train = np.array([pdata[i].values[-30:]])\n",
    "        X_test = np.array([pdata[i].values[30:]])\n",
    "        \n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mu.append((y_pred[0][-1] - X_test[0][-1]) / X_test[0][-1])\n",
    "    return pd.Series(mu, index=pdata.columns) * 100\n",
    "\n",
    "def var_from_lgbm(pdata):\n",
    "    var = []\n",
    "    preds = []\n",
    "    \n",
    "    def create_ds(data, ws, h):\n",
    "        X, y = [], []\n",
    "        for i in range(len(data) - ws - h + 1):\n",
    "            X.append(data[i:i + ws])\n",
    "            y.append(data[i + ws:i + ws + h])\n",
    "        return np.array(X), np.array(y)\n",
    "    \n",
    "    for i in pdata.columns:\n",
    "        X, y = create_ds(pdata[i].values, ws=60, h=30)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        model = LGBMRegressor(objective='regression'\n",
    "                             , metric='rmse'\n",
    "                             , boosting_type='gbdt'\n",
    "                             , num_leaves=31\n",
    "                             , learning_rate=0.01\n",
    "                             , n_estimators=1000\n",
    "                             , verbose=-1)\n",
    "\n",
    "        model.fit(X_train, y_train[:, 0], eval_set=[(X_train, y_train[:, 0]),\n",
    "                                                   (X_test, y_test[:, 0])])\n",
    "        pred = model.predict(X_test)\n",
    "        var.append(np.var(pd.Series(pred).pct_change()))\n",
    "    clear_output(wait=True)   \n",
    "    return np.array(var) * 1000\n",
    "\n",
    "def encoder_corr(p=1):\n",
    "    if p <= 41:\n",
    "        x = np.loadtxt('correlation_analysis/intermediate_data/decoder/X_encoded_train_copula_large_list%s.gz' %p, delimiter=',')\n",
    "    else:\n",
    "        p = p - 42\n",
    "        x = np.loadtxt('correlation_analysis/intermediate_data/decoder/X_encoded_val_copula_large_list%s.gz' %p, delimiter=',')\n",
    "    return np.corrcoef(x)\n",
    "\n",
    "def var_lgbm_encoder_corr(pdata, p=1):\n",
    "    var = var_from_lgbm(pdata)\n",
    "    corr_m = encoder_corr(p=p)\n",
    "    cov_m = pd.DataFrame(np.diag(var) @ corr_m @ np.diag(var))\n",
    "    cov_m.index = pdata.columns\n",
    "    cov_m.columns = pdata.columns\n",
    "    return cov_m\n",
    "\n",
    "def get_r_cvar_portfolio(pdata, predicted_days=30, n_sim=1000, mu=None, sigma=None, corr_matrix=None, weight=[]):\n",
    "    n_assets = pdata.shape[1]\n",
    "    history_days = pdata.shape[0]\n",
    "    predicted_days = predicted_days\n",
    "    total_days = history_days + predicted_days\n",
    "    n_sim = n_sim\n",
    "    \n",
    "    if mu is None:\n",
    "        mu = pdata.mean().values\n",
    "    if sigma is None:    \n",
    "        sigma = np.diag(pdata.cov())\n",
    "    if corr_matrix is None:\n",
    "        corr_matrix = pdata.corr()\n",
    "        \n",
    "    theta = sigma / (2 * mu)\n",
    "    \n",
    "    S0 = pdata.values\n",
    "    try:\n",
    "        L = np.linalg.cholesky(corr_matrix)\n",
    "    except:\n",
    "        corr_matrix_new = corr_matrix + 1e-10 * np.eye(corr_matrix.shape[0])\n",
    "        L = np.linalg.cholesky(corr_matrix_new)\n",
    "        \n",
    "    dt = 1/history_days\n",
    "    sqrt_dt = np.sqrt(dt)\n",
    "    \n",
    "    paths = np.zeros((n_sim, total_days, n_assets))\n",
    "    paths[:, :history_days, :] = S0\n",
    "    \n",
    "    for i in range(n_sim):\n",
    "        Z = np.random.normal(0, 1, size=(predicted_days, n_assets))\n",
    "        corr_Z = Z @ L.T\n",
    "\n",
    "        for t in range(history_days, total_days):\n",
    "            for k in range(n_assets):\n",
    "                drift = theta[k] * (mu[k] - paths[i, t, k]) * dt\n",
    "                diffusion = sigma[k] * sqrt_dt * corr_Z[t-history_days, k]\n",
    "                paths[i, t, k] = paths[i, t-1, k] + drift + diffusion\n",
    "                \n",
    "    net_wealths = []\n",
    "    for p in range(len(paths)):\n",
    "        period_wealths = [sum((np.array(weight) * 1000000) / paths[p][-31:][0])]\n",
    "        p0 = [paths[p][-31:][0]]\n",
    "        qnt0 = ((np.array(weight) * 1000000) / paths[p][-31:][0] ).astype(int)\n",
    "        for day in range(31):\n",
    "            p1 = paths[p][-31:][day]\n",
    "            w1 = sum(qnt0 * p1)\n",
    "            period_wealths.append(w1)\n",
    "        net_wealths.append(period_wealths)\n",
    "        \n",
    "    cvars = []\n",
    "    for i in range(len(net_wealths)):\n",
    "        cvar = np.mean(np.sort((np.array(net_wealths[i][1:]) / 1000000) - 1)[:3])\n",
    "        cvars.append(cvar)\n",
    "        \n",
    "    pseudo_portfolio_returns = []\n",
    "    for i in range(len(net_wealths)):\n",
    "        pseudo_portfolio_returns.append(net_wealths[i][-1] / 1000000 * 100 - 100)\n",
    "        \n",
    "    return np.mean(pseudo_portfolio_returns), np.mean(cvars)\n",
    "\n",
    "def get_max_r_cvar_portfolio(pdata, p=1):\n",
    "    mu = xgboost_exp_ret(pdata)\n",
    "    cov_m = var_lgbm_encoder_corr(pdata, p=p)\n",
    "    ef_dots = get_ef_dots(mu, cov_m)\n",
    "    pseudo_returns = []\n",
    "    pseudo_cvars = []\n",
    "    pseudo_r_cvar = []\n",
    "    pseudo_r_cvar_all = []\n",
    "    for w in ef_dots[2]:\n",
    "        pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                       , predicted_days=30\n",
    "                                                       , n_sim=1000\n",
    "                                                       , mu=None\n",
    "                                                       , sigma=None\n",
    "                                                       , corr_matrix=None\n",
    "                                                       , weight=w)\n",
    "        pseudo_returns.append(pseudo_ret)\n",
    "        pseudo_cvars.append(pseudo_cvar)\n",
    "        pseudo_r_cvar.append(pseudo_ret / -pseudo_cvar)\n",
    "        pseudo_r_cvar_all.append([pseudo_ret, pseudo_cvar])\n",
    "    max_r_cvar = pseudo_r_cvar.index(max(pseudo_r_cvar))\n",
    "    return ef_dots, [ef_dots[0][max_r_cvar], ef_dots[1][max_r_cvar], ef_dots[2][max_r_cvar]], mu, cov_m, pseudo_r_cvar, pseudo_r_cvar_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bece34ba",
   "metadata": {},
   "source": [
    "Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b24297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "328ffbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 37s\n",
      "Wall time: 9min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 1 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio = get_min_risk_portfolio(pdata_pct_m)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # / 100\n",
    "                    , portfolio_treynor_per # / 1000000\n",
    "                    , portfolio_sortino_per # / 100\n",
    "                    , portfolio_stuzer_per # / 10000\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # / 100\n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b59f86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 41s\n",
      "Wall time: 9min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio = get_max_sharpe_portfolio(pdata_pct_m)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # / 1000\n",
    "                    , portfolio_treynor_per # / 1000000\n",
    "                    , portfolio_sortino_per # / 100\n",
    "                    , portfolio_stuzer_per # / 100000\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # / 100\n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d694ddc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40min 24s\n",
      "Wall time: 39min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 3 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio, _, _ = get_max_treynor_portfolio(pdata_pct_m, msci_y['MSCI'])\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # / 10\n",
    "                    , portfolio_treynor_per # / 10000000\n",
    "                    , portfolio_sortino_per # / 10\n",
    "                    , portfolio_stuzer_per # / 10000\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per # / 10\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # / 100\n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9484ae45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 17min 30s\n",
      "Wall time: 16min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 4 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio, _, _ = get_max_sortino_portfolio(pdata_pct_m, msci_y['MSCI'], r_f)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # / 10\n",
    "                    , portfolio_treynor_per # / 1000\n",
    "                    , portfolio_sortino_per # / 10\n",
    "                    , portfolio_stuzer_per # / 100\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # \n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71b9502",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 5 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(0, 61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    try:\n",
    "        _, portfolio, _, _ = get_max_stuzer_portfolio(pdata, pdata_pct, pdata_pct_m, r_f, p=i)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # \n",
    "                    , portfolio_treynor_per # \n",
    "                    , portfolio_sortino_per # \n",
    "                    , portfolio_stuzer_per # \n",
    "                    , portfolio_modiliani_per # \n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # \n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3778376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13min 3s\n",
      "Wall time: 10min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 6 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio, _, _, _ = get_min_var_portfolio(pdata, pdata_pct, pdata_pct_m, p=i, alpha=0.95, days=30)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # \n",
    "                    , portfolio_treynor_per # / 100000\n",
    "                    , portfolio_sortino_per # \n",
    "                    , portfolio_stuzer_per # / 100\n",
    "                    , portfolio_modiliani_per # / 10000000000\n",
    "                    , portfolio_var_per # * 10\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # \n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e616b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 23min 7s\n",
      "Wall time: 20min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 7 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio, _, _, _ = get_min_cvar_portfolio(pdata_pct, p=i, alpha=0.95)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "                                                   , predicted_days=30\n",
    "                                                   , n_sim=1000\n",
    "                                                   , mu=None\n",
    "                                                   , sigma=None\n",
    "                                                   , corr_matrix=None\n",
    "                                                   , weight=w)\n",
    "    portfolio_r_cvar_per.append(pseudo_ret / -pseudo_cvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # / 10\n",
    "                    , portfolio_treynor_per # / 1000000\n",
    "                    , portfolio_sortino_per # / 100\n",
    "                    , portfolio_stuzer_per # / 10000\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # / 100\n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6a2f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 23h 42min 3s\n",
      "Wall time: 14h 51min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 8 portfolio\n",
    "\n",
    "portfolio_return_itg = [] #\n",
    "portfolio_return_per = [] #\n",
    "portfolio_wealth_per = [] #\n",
    "portfolio_cov_per = [] #\n",
    "\n",
    "portfolio_sharpe_per = [] #\n",
    "portfolio_treynor_per = [] #\n",
    "portfolio_sortino_per = [] #\n",
    "portfolio_stuzer_per = [] #\n",
    "portfolio_modiliani_per = [] #\n",
    "portfolio_var_per = [] #\n",
    "portfolio_cvar_per = [] #\n",
    "portfolio_r_cvar_per = [] #\n",
    "portfolio_alpha_per = [] #\n",
    "\n",
    "portfolio_weights = [] #\n",
    "\n",
    "for i in range(61):\n",
    "    pdata = period_data[i]\n",
    "    pdata_pct = period_data_pct[i]\n",
    "    pdata_pct_m = period_data_pct_m[i]\n",
    "    r_f = period_rate[i]\n",
    "    msci_y = period_msci[i]\n",
    "    \n",
    "    print(i)\n",
    "    print('start')\n",
    "    mu = pdata_pct_m.mean()\n",
    "    cov_m = pdata_pct_m.cov()\n",
    "    _, portfolio, _, _, _, rcvar = get_max_r_cvar_portfolio(pdata, p=i)\n",
    "    \n",
    "    #return, cov, weights\n",
    "    print(1)\n",
    "    portfolio_return_per.append(portfolio[0])\n",
    "    portfolio_cov_per.append(portfolio[1])\n",
    "    portfolio_weights.append(portfolio[2])\n",
    "    w = np.array(portfolio[2])\n",
    "    \n",
    "    #wealth periodic\n",
    "    print(2)\n",
    "    if i == 0:\n",
    "        quant = (w * 1000000 /  pdata.iloc[-1].values).astype(int)\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "    else:\n",
    "        portfolio_wealth_per.append(sum(quant * pdata.iloc[-1].values))\n",
    "        quant = (w * portfolio_wealth_per[-1] /  pdata.iloc[-1].values).astype(int) \n",
    "    \n",
    "    #itg return\n",
    "    print(3)\n",
    "    if i == 60:\n",
    "        portfolio_return_itg.append(portfolio_wealth_per[-1] / portfolio_wealth_per[0])\n",
    "        \n",
    "    #sharpe\n",
    "    print(4)\n",
    "    portfolio_sharpe_per.append( (w @ (mu.values - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #treynor\n",
    "    print(5)\n",
    "    betas = get_asset_betas(pdata_pct_m, msci_y['MSCI'])\n",
    "    portfolio_treynor_per.append( (mu - r_f) @ w / (w @ betas.T) )\n",
    "    \n",
    "    #sortino\n",
    "    print(6)\n",
    "    portfolio_sortino_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) )\n",
    "    \n",
    "    #stuzer\n",
    "    print(7)\n",
    "    def st_f(I, mu, r_f, w):\n",
    "        return -np.log(np.mean(np.exp(I * w @ (mu - r_f))))\n",
    "    res = minimize(lambda I: -st_f(I, mu, r_f, w), x0=1.0, method='BFGS')\n",
    "    I_st = res.x[0]\n",
    "    portfolio_stuzer_per.append( (w @ (mu - r_f)) / np.sqrt(w @ cov_m @ w) * np.sqrt(2 * abs(I_st)) )\n",
    "    \n",
    "    #modiliani\n",
    "    print(8)\n",
    "    portfolio_modiliani_per.append((portfolio[0] - r_f) * (np.var(msci_y['MSCI']) / np.var(portfolio_return_per)) + r_f)\n",
    "    \n",
    "    #var\n",
    "    print(9)\n",
    "    alpha=0.95\n",
    "    days=30\n",
    "    var = abs(portfolio[0] * days - abs(norm.ppf(1-alpha)) * portfolio[1] * np.sqrt(days)) / 100\n",
    "    portfolio_var_per.append(portfolio_wealth_per[-1] * var)\n",
    "    \n",
    "    #cvar\n",
    "    print(10)\n",
    "    alpha=0.95\n",
    "    portfolio_ret = pdata_pct @ w\n",
    "    var_level = int((1 - alpha) * len(mu))\n",
    "    sorted_ret = np.sort(portfolio_ret)\n",
    "    var = -sorted_ret[var_level]\n",
    "    cvar = -np.mean(sorted_ret[:var_level])\n",
    "    portfolio_cvar_per.append(portfolio_wealth_per[-1] * cvar)\n",
    "    \n",
    "    #r/cvar\n",
    "    print(11)\n",
    "    #pseudo_ret, pseudo_cvar = get_r_cvar_portfolio(pdata\n",
    "    #                                               , predicted_days=30\n",
    "    #                                               , n_sim=1000\n",
    "    #                                               , mu=None\n",
    "    #                                               , sigma=None\n",
    "    #                                               , corr_matrix=None\n",
    "    #                                               , weight=w)\n",
    "    portfolio_r_cvar_per.append(rcvar)\n",
    "    \n",
    "    #alpha\n",
    "    print(12)\n",
    "    r_m = (msci_y.iloc[0, 0] - msci_y.iloc[-1, 0]) / msci_y.iloc[-1, 0]\n",
    "    if i == 0:\n",
    "        b_p = 0\n",
    "    else:\n",
    "        msci_y_pct = msci_y.pct_change().dropna()['MSCI']\n",
    "        if len(portfolio_return_per) <= len(msci_y_pct):\n",
    "            x = len(portfolio_return_per)\n",
    "            b_p = np.cov(portfolio_return_per, msci_y_pct[:x])[0][0] / np.var(msci_y_pct)\n",
    "        else:\n",
    "            x = len(msci_y_pct)\n",
    "            b_p = np.cov(portfolio_return_per[-x:], msci_y_pct)[0][0] / np.var(msci_y_pct)\n",
    "        \n",
    "    portfolio_alpha_per.append(portfolio[0] - (r_f + (r_m - r_f) * b_p))\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "all_results.append([portfolio_return_itg\n",
    "                    , portfolio_return_per\n",
    "                    , portfolio_wealth_per\n",
    "                    , portfolio_cov_per\n",
    "                    , portfolio_sharpe_per # \n",
    "                    , portfolio_treynor_per # / 10000\n",
    "                    , portfolio_sortino_per # \n",
    "                    , portfolio_stuzer_per # / 100\n",
    "                    , portfolio_modiliani_per # / 10000000\n",
    "                    , portfolio_var_per\n",
    "                    , portfolio_cvar_per \n",
    "                    , portfolio_r_cvar_per # \n",
    "                    , portfolio_alpha_per\n",
    "                    , portfolio_weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed49a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_mod = []\n",
    "\n",
    "for kk, port in enumerate(all_results):\n",
    "    p_ms = []\n",
    "    for gg, metr in enumerate(port):\n",
    "        if kk == 0:\n",
    "            if gg == 4:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 1000000\n",
    "            if gg == 6:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 11:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "        if kk == 1:\n",
    "            if gg == 4:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 1000\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 1000000\n",
    "            if gg == 6:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100000\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 11:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "        if kk == 2:\n",
    "            if gg == 4:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 6:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 9:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 11:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "        if kk == 3:\n",
    "            if gg == 4:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 1000\n",
    "            if gg == 6:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "        if kk == 4:\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100000\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000000\n",
    "            if gg == 9:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr * 10\n",
    "        if kk == 5:\n",
    "            if gg == 4:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 1000000\n",
    "            if gg == 6:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 11:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "        if kk == 6:\n",
    "            if gg == 5:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000\n",
    "            if gg == 7:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 100\n",
    "            if gg == 8:\n",
    "                metr = np.array(metr)\n",
    "                metr = metr / 10000000\n",
    "            if gg == 11:\n",
    "                #metr = np.array(metr)\n",
    "                #metr = [np.mean(i) for i in metr]\n",
    "                pre_metr = []\n",
    "                for ii in metr:\n",
    "                    pre_metr.append(np.mean([iii[0] / iii[1] for iii in ii]))\n",
    "                metr = np.array(pre_metr)\n",
    "                \n",
    "        p_ms.append(metr)\n",
    "    all_results_mod.append(p_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd8675c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "655198b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('portf_all.pkl', 'wb') as f:\n",
    "    pickle.dump(all_results_mod, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7253601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
